{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JvzAZolMFhk"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbNNXvaFIcwv"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas \n",
    "import keras\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSkxvh6mMikX"
   },
   "source": [
    "## Fixing Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BRD5PEzIcw4"
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPslcaR5MPX3"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLpuWw6lIcw9"
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aek2PSaG_Q1g"
   },
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPnHlziNNxWs"
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yotKN1bCJ4zm"
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "reverse_encoding = encoder.inverse_transform(encoded_Y) # reversing the encoding for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lmkufs78cDHU"
   },
   "outputs": [],
   "source": [
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpJ7Ft37aymx"
   },
   "source": [
    "# Baseline Model (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMLJdFSFIcxG"
   },
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "  # create model, write code below\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(60, activation ='relu', input_shape = (X.shape[1],))) # number of features (60) are used as vector in input shape\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "\t\n",
    "  # Compile model, write code below\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\t\n",
    "  return model\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1O4WdlyE8Xe"
   },
   "source": [
    "## Evaluatuon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "efc4RlIPbJH2",
    "outputId": "739bded7-ffac-4eec-d837-858eab45761d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Results: 83.71% (6.13%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_b5XSX3gaGcU",
    "outputId": "29ce6b9a-9863-4dfd-dfb0-409f017869b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "royfBjEIYg1j"
   },
   "source": [
    "# Smaller Model (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "_nwj-issWRkn",
    "outputId": "994f8849-241c-4ff5-b69d-c310074b1693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Smaller: 85.06% (7.61%)\n"
     ]
    }
   ],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(30, activation ='relu', input_shape = (X.shape[1],))) # number of features (60) are used as vector in input shape\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "\t# Compile model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9Yo5-l7Ycv1"
   },
   "source": [
    "# Larger Model (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LM4HF3RjXTLt",
    "outputId": "eb973d81-f6df-4d0a-d100-8cbc54de3dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 83.59% (4.65%)\n"
     ]
    }
   ],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(60, activation ='relu', input_shape = (X.shape[1],))) # number of features (60) are used as vector in input shape\n",
    "  model.add(layers.Dense(30, activation ='relu'))\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "\t# Compile model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YoPz-Q9YWRx"
   },
   "source": [
    "# Fully Scaled (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7pJCAhYKJPWI",
    "outputId": "1e4af824-8bf3-47e9-f9d0-38e890ec500e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled: 87.52% (6.57%)\n"
     ]
    }
   ],
   "source": [
    "# fully scaled up model\n",
    "def fully_scaled():\n",
    "  # create model\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(512, activation ='relu', input_shape = (X.shape[1],))) # number of features (60) are used as vector in input shape\n",
    "  model.add(layers.Dense(256, activation ='relu'))\n",
    "  model.add(layers.Dense(128, activation ='relu'))\n",
    "  model.add(layers.Dense(128, activation ='relu'))\n",
    "  model.add(layers.Dense(64, activation ='relu'))\n",
    "  model.add(layers.Dense(32, activation ='relu'))\n",
    "  model.add(layers.Dense(16, activation ='relu'))\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "  # Compile model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=fully_scaled, epochs=300, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Fully Scaled: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fcZgh2tQ5qV"
   },
   "source": [
    "# Tuned Model (Sequential)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Trial Combination \n",
    "\n",
    "### Tuned: 84.52% (5.93%) l1 =90, l2= 60, output= 1\n",
    "\n",
    "### Tuned: 85.04% (6.41%) 100 100 1\n",
    "\n",
    "### Tuned: 85.06% (7.03%) 90 35 1\n",
    "\n",
    "### Tuned: 85.13% (7.79%) 80 30 1\n",
    "\n",
    "### Tuned: 85.54% (6.49%) 100 30 1\n",
    "\n",
    "### Tuned: 85.56% (8.58%) 60 32 16 8 1\n",
    "\n",
    "### Tuned: 85.97% (5.65%) 90 40 1\n",
    "\n",
    "### Tuned: 86.04% (9.79%) 512 128 64 16 1 \n",
    "\n",
    "### Tuned: 86.54% (6.74%) 90 20 1\n",
    "\n",
    "### *Tuned: 86.99% (5.43%) 90 30 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Loss_Func = binary_crossentropy, Optimizer = Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ouJ-CoHtJ60i",
    "outputId": "a7dd4668-bbde-49b4-dc03-bb82927a5e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned_1: 86.99% (5.43%)\n"
     ]
    }
   ],
   "source": [
    "def tuned_model_1():\n",
    "  # create model, write code below\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(90, activation ='relu', input_shape = (X.shape[1],)))\n",
    "  model.add(layers.Dense(30, activation ='relu'))\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "\t\n",
    "  # Compile model, write code below\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=tuned_model_1, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Tuned_1: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjrTGj4FY7-H"
   },
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvGjqagUY5dF"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BGIDDzSQcQs2",
    "outputId": "a9b5de65-f6c3-4f35-f6dc-5f8740ecdc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_functional():\n",
    "  input_tensor = Input(shape=(60,))\n",
    "  x = layers.Dense(60, activation='relu')(input_tensor)\n",
    "#x = layers.Dense(1, activation='relu')(x)\n",
    "  output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "  model = Model(input_tensor, output_tensor)\n",
    "  \n",
    "  # Compile the model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_functional, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gNO5MvZFnzHc",
    "outputId": "3e45fbff-7e80-4a99-fe33-27ff78cff16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.06% (7.61%)\n"
     ]
    }
   ],
   "source": [
    "def create_smaller_functional():\n",
    "  input_tensor = Input(shape=(60,))\n",
    "  x = layers.Dense(30, activation='relu')(input_tensor)\n",
    "  output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "  model = Model(input_tensor, output_tensor)\n",
    "  \n",
    "  # Compile the model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# evaluate smaller model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller_functional, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X1nd7Jpc1MYz",
    "outputId": "2411131e-49c9-4d04-b9ef-b64244880c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 83.59% (4.65%)\n"
     ]
    }
   ],
   "source": [
    "# larger model\n",
    "def create_larger_functional():\n",
    "# create model\n",
    "  input_tensor = Input(shape=(60,))\n",
    "  x = layers.Dense(60, activation='relu')(input_tensor)\n",
    "  x = layers.Dense(30, activation='relu')(x)\n",
    "  output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "  model = Model(input_tensor, output_tensor)\n",
    "  \n",
    "# Compile model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model\n",
    "# evaluate larger model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger_functional, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pNtrzFlIvtYY",
    "outputId": "d279ed3e-e774-46db-a2c5-37fd39e2eb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled: 84.09% (8.11%)\n"
     ]
    }
   ],
   "source": [
    "def create_fully_scaled_functional():\n",
    "  input_tensor = Input(shape=(60,))\n",
    "  x = layers.Dense(512, activation='relu')(input_tensor)\n",
    "  x = layers.Dense(256, activation='relu')(x)\n",
    "  x = layers.Dense(128, activation='relu')(x)\n",
    "  x = layers.Dense(128, activation='relu')(x)\n",
    "  x = layers.Dense(64, activation='relu')(x)\n",
    "  x = layers.Dense(32, activation='relu')(x)\n",
    "  x = layers.Dense(16, activation='relu')(x)\n",
    "  output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "  model = Model(input_tensor, output_tensor)\n",
    "  \n",
    "  # Compile the model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "# evaluate fully scaled model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_fully_scaled_functional, epochs=300, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Fully Scaled: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8PsKOXpRxDty",
    "outputId": "d07950f3-92c7-48ba-a8f6-1c2bf7302946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned: 86.49% (7.11%)\n"
     ]
    }
   ],
   "source": [
    "def create_tuned_model_functional():\n",
    "  # create model, write code below\n",
    "  input_tensor = Input(shape=(60,))\n",
    "  x = layers.Dense(90, activation='relu')(input_tensor)\n",
    "  x = layers.Dense(30, activation='relu')(x)\n",
    "  output_tensor = layers.Dense(1, activation='sigmoid')(x)\n",
    "# The Model class turns an input tensor and output tensor into a model\n",
    "  model = Model(input_tensor, output_tensor)\n",
    "  \n",
    "  # Compile the model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "# evaluate tuned model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_tuned_model_functional, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Tuned: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfV0vKPk4tT1"
   },
   "source": [
    "# Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mBBrbnpIzvZy",
    "outputId": "5e9c50e1-31a2-4f2d-a624-09f16be1c510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "class MyBaselineModel(keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(MyBaselineModel,self).__init__('my_baseline')\n",
    "  #  self.units = 60\n",
    "    self.dense1 = keras.layers.Dense(60, activation='relu')\n",
    "    self.dense2 = keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    return self.dense2(x)\n",
    "    \n",
    "def create_baseline_subclass_model():\n",
    "  inputs = keras.Input(shape=(60,))\n",
    "  mymodel = MyBaselineModel()\n",
    "  outputs = mymodel.call(inputs)\n",
    "    \n",
    "  model = keras.Model(inputs,outputs)\n",
    "    \n",
    "# compiling model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline_subclass_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DdgX32Ckcp8t",
    "outputId": "06cb6614-5683-4e6c-e819-e7216f08a55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 83.09% (6.41%)\n"
     ]
    }
   ],
   "source": [
    "class MySmallerModel(keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(MySmallerModel,self).__init__('my_Smaller')\n",
    "    self.dense1 = keras.layers.Dense(30, activation='relu')\n",
    "    self.dense2 = keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    return self.dense2(x)\n",
    "    \n",
    "def create_smaller_subclass_model():\n",
    "  inputs = keras.Input(shape=(60,))\n",
    "  mymodel = MySmallerModel()\n",
    "  outputs = mymodel.call(inputs)\n",
    "    \n",
    "  model = keras.Model(inputs,outputs)\n",
    "    \n",
    "# compiling model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# evaluate smaller model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller_subclass_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K_o8w6zWc7ZD",
    "outputId": "83dea032-2660-435c-c925-ceb77ce35637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 85.09% (7.25%)\n"
     ]
    }
   ],
   "source": [
    "class MylargerModel(keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(MylargerModel,self).__init__('my_larger')\n",
    "    self.dense1 = keras.layers.Dense(60, activation='relu')\n",
    "    self.dense2 = keras.layers.Dense(30, activation='relu')\n",
    "    self.dense3 = keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    return self.dense3(x)\n",
    "    \n",
    "def create_larger_subclass_model():\n",
    "  inputs = keras.Input(shape=(60,))\n",
    "  mymodel = MylargerModel()\n",
    "  outputs = mymodel.call(inputs)\n",
    "    \n",
    "  model = keras.Model(inputs,outputs)\n",
    "    \n",
    "# compiling model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# evaluate larger model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger_subclass_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dh9M1ya0oZFy",
    "outputId": "77c8818b-559b-4564-cfd9-366839dc64d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled: 86.04% (6.28%)\n"
     ]
    }
   ],
   "source": [
    "class MyFullyScaledModel(keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(MyFullyScaledModel,self).__init__('my_FullyScaled')\n",
    "    self.dense1 = keras.layers.Dense(512, activation='relu')\n",
    "    self.dense2 = keras.layers.Dense(256, activation='relu')\n",
    "    self.dense3 = keras.layers.Dense(128, activation='relu')\n",
    "    self.dense4 = keras.layers.Dense(128, activation='relu')\n",
    "    self.dense5 = keras.layers.Dense(64, activation='relu')\n",
    "    self.dense6 = keras.layers.Dense(32, activation='relu')\n",
    "    self.dense7 = keras.layers.Dense(16, activation='relu')\n",
    "    self.dense8 = keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    x = self.dense3(x)\n",
    "    x = self.dense4(x)\n",
    "    x = self.dense5(x)\n",
    "    x = self.dense6(x)\n",
    "    x = self.dense7(x)\n",
    "    return self.dense8(x)\n",
    "    \n",
    "def create_Fully_Scaled_subclass_model():\n",
    "  inputs = keras.Input(shape=(60,))\n",
    "  mymodel = MyFullyScaledModel()\n",
    "  outputs = mymodel.call(inputs)\n",
    "    \n",
    "  model = keras.Model(inputs,outputs)\n",
    "    \n",
    "# compiling model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# evaluate fully scaled model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_Fully_Scaled_subclass_model, epochs=300, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Fully Scaled: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NBZB8A4FK-HZ",
    "outputId": "39dfe5db-ac87-4fee-9d91-86d31b03c42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned: 86.90% (9.89%)\n"
     ]
    }
   ],
   "source": [
    "class MyTunedModel(keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(MyTunedModel,self).__init__('my_TunedModel')\n",
    "    self.dense1 = keras.layers.Dense(90, activation='relu')\n",
    "    self.dense2 = keras.layers.Dense(30, activation='relu')\n",
    "    self.dense3 = keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    x = self.dense2(x)\n",
    "    return self.dense3(x)\n",
    "    \n",
    "def create_Tuned_subclass_model():\n",
    "  inputs = keras.Input(shape=(60,))\n",
    "  mymodel = MyTunedModel()\n",
    "  outputs = mymodel.call(inputs)\n",
    "    \n",
    "  model = keras.Model(inputs,outputs)\n",
    "    \n",
    "# compiling model\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# evaluate tuned model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_Tuned_subclass_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Tuned: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwAH8LrcOv4h"
   },
   "source": [
    "# Without Scikit Learn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ts2Wt8U2ofnJ"
   },
   "outputs": [],
   "source": [
    "def tuned_model():\n",
    "  # create model, write code below\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(90, activation ='relu', input_shape = (X.shape[1],)))\n",
    "  model.add(layers.Dense(30, activation ='relu'))\n",
    "  model.add(layers.Dense(1, activation ='sigmoid'))\n",
    "\t\n",
    "  # Compile model, write code below\n",
    "  model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glwDCeTVojpP"
   },
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "dataframe = shuffle(dataframe)\n",
    "\n",
    "# checking data\n",
    "dataset = dataframe.values\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "reverse_encoding = encoder.inverse_transform(encoded_Y) # reversing the encoding for fun\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "tR_h0oYFIcxQ",
    "outputId": "7fa7de77-71fa-41db-ee18-6180d58818f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 90.00% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 90.00% (Error)Std (0.00%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 88.33% (Error)Std (2.36%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 90.00% (Error)Std (3.54%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 89.00% (Error)Std (3.74%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 87.50% (Error)Std (4.79%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 85.00% (Error)Std (7.56%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 85.00% (Error)Std (7.07%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 85.56% (Error)Std (6.85%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 85.50% (Error)Std (6.50%)\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "num_val_samples = len(X) // 10\n",
    "num_epochs = 100\n",
    "all_scores = numpy.array([])\n",
    "\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i+1)\n",
    "  # prepare the validation data: data from partition # k\n",
    "  val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = encoded_Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "  # prepare the training data: data from data - k\n",
    "  partial_train_data = numpy.concatenate(                    \n",
    "      [X[:i * num_val_samples],\n",
    "      X[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  partial_train_targets = numpy.concatenate(\n",
    "      [encoded_Y[:i * num_val_samples],\n",
    "      encoded_Y[(i + 1 ) * num_val_samples:]],\n",
    "  axis = 0)\n",
    "  \n",
    "  # Build the Keras Models (already commpiled)\n",
    "  model = tuned_model()\n",
    "  \n",
    "  # Train the model (in silence mode, verbose = 0)\n",
    "  history = model.fit(partial_train_data, partial_train_targets, epochs = num_epochs, batch_size = 5, verbose = 0)\n",
    "  \n",
    "  # Evaluate the model on the validation data\n",
    "  val_binary_crossentropy, val_accuracy = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "  \n",
    "  all_scores = numpy.append(all_scores, val_accuracy)\n",
    "  print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (all_scores.mean()*100, all_scores.std()*100))\n",
    "       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Navy_Binary_Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
